{"cells":[{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1000, 1000)\n"]},{"data":{"text/plain":["tensor(1.)"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["from PIL import Image\n","from PIL.ImageOps import grayscale\n","import numpy as np\n","from torchvision.transforms import GaussianBlur, RandomRotation, ToTensor, Compose\n","import torch\n","import random\n","img = Image.open(\"/home/jan/ADLCV/HumanMotionGeneration/dataset/HumanML3D/sketches/000003/000003_frame_0.png\")\n","print(img.size)\n","img = img.crop((200, 200, 800, 800))\n","img = img.resize((200,200))\n","img = grayscale(img)\n","\n","transforms = Compose([\n","    RandomRotation([-20, 20], fill=255),\n","    GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.5)),\n","    ToTensor()\n","    ]\n","    )\n","\n","img = transforms(img)\n","img.max()\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from data_loaders.utils import opt\n","import model\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["(116, 263)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","\n","dt = np.load('/home/jan/ADLCV/HumanMotionGeneration/dataset/HumanML3D/new_joint_vecs/000000.npy')\n","dt.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"mdm","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"}},"nbformat":4,"nbformat_minor":2}
